import pandas as pd
import numpy as np
from sklearn import model_selection
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
ds=pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data",delimiter=",")

ds.shape
(149, 5)
ds.columns=["sepal_len","sepal_width","petal_len","petal_width","species"]
ds.head()
sepal_len	sepal_width	petal_len	petal_width	species
0	4.9	3.0	1.4	0.2	Iris-setosa
1	4.7	3.2	1.3	0.2	Iris-setosa
2	4.6	3.1	1.5	0.2	Iris-setosa
3	5.0	3.6	1.4	0.2	Iris-setosa
4	5.4	3.9	1.7	0.4	Iris-setosa
data=ds.values #convert to 2-D matrix

X=data[:,0:-1]
Y=data[:,-1]
val_size=0.25
seed=3
x_train, x_test, y_train, y_test = model_selection.train_test_split(X,Y,test_size=val_size,random_state=seed)
dtree = DecisionTreeClassifier()
dtree.fit(x_train,y_train)
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')
predictions=dtree.predict(x_test)
predictions
array(['Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',
       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',
       'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica',
       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica',
       'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',
       'Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',
       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',
       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',
       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',
       'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',
       'Iris-versicolor', 'Iris-versicolor'], dtype=object)
print("Accuracy using Random Subsampling : ", accuracy_score(y_test,predictions))
Accuracy using Random Subsampling :  0.9473684210526315
confusion_matrix(y_test,predictions)
array([[15,  0,  0],
       [ 0, 13,  1],
       [ 0,  1,  8]])
print("Classification Report : \n\n", classification_report(y_test,predictions))
Classification Report : 

                  precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        15
Iris-versicolor       0.93      0.93      0.93        14
 Iris-virginica       0.89      0.89      0.89         9

       accuracy                           0.95        38
      macro avg       0.94      0.94      0.94        38
   weighted avg       0.95      0.95      0.95        38

eval = 'accuracy'
seed = 4
model=DecisionTreeClassifier()
kfold = model_selection.KFold(n_splits=5, shuffle= True, random_state= seed)
results = model_selection.cross_val_score(model, X, Y, cv= kfold, scoring= eval)
print("Accuracy using Cross Validation : ",results.mean())
Accuracy using Cross Validation :  0.9533333333333334
#K-NEIGHBORS CLASSIFIER
#Computing K-Neighbours Classifier Using Random Subsampling
classifier = KNeighborsClassifier()
classifier.fit(x_train,y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,
                     weights='uniform')
predictions = classifier.predict(x_test)
print("Accuracy using K-Neighbours classifier : ",accuracy_score(y_test,predictions))
Accuracy using K-Neighbours classifier :  0.9736842105263158
print("Confusion Matrix : \n\n",confusion_matrix(y_test,predictions))
Confusion Matrix : 

 [[15  0  0]
 [ 0 14  0]
 [ 0  1  8]]
print("Classification Report : \n\n",classification_report(y_test, predictions))
Classification Report : 

                  precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        15
Iris-versicolor       0.93      1.00      0.97        14
 Iris-virginica       1.00      0.89      0.94         9

       accuracy                           0.97        38
      macro avg       0.98      0.96      0.97        38
   weighted avg       0.98      0.97      0.97        38

#Computing K-Neighbours Classifier Using Cross Validation

eval = 'accuracy'
seed = 4
model= KNeighborsClassifier()
kfold = model_selection.KFold(n_splits=5, shuffle= True, random_state= seed)
results = model_selection.cross_val_score(model, X, Y, cv= kfold, scoring= eval)
print("Accuracy using Cross Validation : ",results.mean())
Accuracy using Cross Validation :  0.9597701149425287
#cOMPARISONS
seed = 4
models = []

models.append(('KNN',KNeighborsClassifier()))
models.append(('CART',DecisionTreeClassifier()))

scoring='accuracy'

results = []

for name, model in models:
    kfold = model_selection.KFold(n_splits=5, shuffle= True, random_state= seed)
    algo_result = model_selection.cross_val_score(model, X, Y, cv= kfold, scoring= eval)
    results.append(algo_result)
    str = "%s : %f" % (name, algo_result.mean())
    print(str)
KNN : 0.959770
CART : 0.946667
